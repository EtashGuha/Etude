<tei>
	<teiHeader>
	<fileDesc xml:id="549"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Informing Memory Operations: Providing Memory <lb/>Performance Feedback in Modern Processors <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Mark Horowitz Margaret Martonosi Todd C. Mowry Michael D. Smith <lb/></docAuthor></byline>
		<byline><affiliation>Computer Systems Department of Department of Electrical Division of <lb/>Laboratory Electrical Engineering and Computer Engineering Applied Sciences <lb/>Stanford University Princeton University University of Toronto Harvard University <lb/></affiliation></byline>
		<email>horowitz@ee.stanford.edu</email> <email> martonosi@princeton.edu</email> <email> tcm@eecg.toronto.edu </email> <email>smith@eecs.harvard.edu <lb/></email>
		<div type="abstract">Abstract <lb/>Memory latency is an important bottleneck in system performance <lb/>that cannot be adequately solved by hardware alone. Several promising software techniques have been shown to address this problem <lb/>successfully in specific situations. However, the generality of these <lb/>software approaches has been limited because current architectures <lb/>do not provide a fine-grained, low-overhead mechanism for <lb/>observing and reacting to memory behavior directly. To fill this <lb/>need, we propose a new class of memory operations called informing memory operations, which essentially consist of a memory <lb/>operation combined (either implicitly or explicitly) with a conditional branch-and-link operation that is taken only if the reference <lb/>suffers a cache miss. We describe two different implementations of <lb/>informing memory operationsone based on a cache-outcome <lb/>condition code and another based on low-overhead trapsand find <lb/>that modern in-order-issue and out-of-order-issue superscalar processors already contain the bulk of the necessary hardware support. <lb/>We describe how a number of software-based memory optimizations can exploit informing memory operations to enhance performance, and look at cache coherence with fine-grained access <lb/>control as a case study. Our performance results demonstrate that <lb/>the runtime overhead of invoking the informing mechanism on the <lb/>Alpha 21164 and MIPS R10000 processors is generally small <lb/>enough to provide considerable exibility to hardware and software designers, and that the cache coherence application has <lb/>improved performance compared to other current solutions. We <lb/>believe that the inclusion of informing memory operations in <lb/>future processors may spur even more innovative performance <lb/>optimizations. <lb/></div>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>