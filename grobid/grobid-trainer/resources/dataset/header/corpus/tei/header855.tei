<tei>
	<teiHeader>
	<fileDesc xml:id="unknown"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Learning Finite Automata Using Local Distinguishing Experiments <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Wei-Min Shen <lb/></docAuthor></byline>
		<byline><affiliation>Microelectronics and Computer Technology Corporation <lb/></affiliation></byline>
		<address>3500 West Balcones Center Drive <lb/>Austin, TX 78759, U.S.A. <lb/></address>
		<div type="abstract">Abstract <lb/>One of the open problems listed in [ Rivest and <lb/>Schapire, 1989 ] is whether and how that the <lb/>copies of L in their algorithm can be combined into one for better performance. This <lb/>paper describes an algorithm called D that <lb/>does that combination. The idea is to represent <lb/>the states of the learned model using observable <lb/>symbols as well as hidden symbols that are constructed during learning. These hidden symbols are created to reflect the distinct behaviors <lb/>of the model states. The distinct behaviors are <lb/>represented as local distinguishing experiments <lb/>(LDEs) (not to be confused with global distinguishing sequences), and these LDEs are created when the learner&apos;s prediction mismatches <lb/>the actual observation from the unknown machine. To synchronize the model with the environment, these LDEs can also be concatenated to form a homing sequence. It can <lb/>be shown that D can learn, with probability <lb/>1 ~, a model that is an *-approximation of <lb/>the unknown machine, in a number of actions <lb/>polynomial in the size of the environment and <lb/></div>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>