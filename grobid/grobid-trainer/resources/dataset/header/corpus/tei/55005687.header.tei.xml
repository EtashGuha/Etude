<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="55005687"/>
	</teiHeader>
	<text xml:lang="en">
		<front>
<lb/>
	<note type="chapter">23<lb/></note>

	<docTitle>
	<titlePart>The Categorization Based Content<lb/> Screening Enabler<lb/></titlePart>
	</docTitle>

	<div type="introduction">Having un-tethered access to knowledge and the ability to share it is undoubtedly one of the<lb/> cornerstones of education, at all stages. The Internet, with the wealth of information it makes<lb/> readily available is an extraordinary tool handed to our generation, leveraging the technological<lb/> advances in electronics, telecommunications, and computer science with incredible benefits. More<lb/> often than not, disruptive technologies, such as the Internet, bring upon progress in quantum leaps.<lb/> But like with any progress, there is a price to pay. Since freedom of expression is something<lb/> that is being universally cherished and the Internet is pretty much a self-regulating ecosystem,<lb/> the proliferation of content that may be controversial, objectionable, and even harmful to society<lb/> cannot be easily denied. As a consequence, digital content promoting pornography, violence, drug<lb/> addictions, hate messages, or abuse is not only tolerated (be it consciously or connivingly) on the<lb/> Internet, but is taking aggressive advantage of the free delivery system that the Internet provides.<lb/> Objectionable content is not only made available to everybody, including children and unsuspecting<lb/> adults, but in many cases such undesired explicit content finds its way through messages, pictures,<lb/> and sound into our homes, schools, and offices, without being directly or even indirectly invited.<lb/> In essence, the problem is more generic in nature: while it is relatively easy to assess what type<lb/> of content is undesirable to reach a specific audience (such as young Internet users), any content<lb/> can be objectionable to one or another, and sometimes it depends on the location one finds oneself<lb/> at, the time of day or the function that one finds oneself involved in at that time. For example,<lb/> employers would like to limit employees&apos; access to content that bears no relationship to their work<lb/> activities, during working hours. An adult who is shopping online for electronic accessories, may<lb/> not want to find, or even worse, be forced to (at least temporarily) deal with pushed content related<lb/> to home mortgage refinancing, although that is something he may consider of interest at other times.<lb/> Where there&apos;s a problem, there is also an opportunity, and so it is not surprising that a number of<lb/> web content filtering solutions have been developed, many of them being commercially available.<lb/> One of the issues with such solutions is that most of them handle only English-language text, while<lb/> the Internet has no boundaries along language-drawn lines. Another issue is how to handle images.<lb/> Should an entire website be filtered and maybe blocked in some cases, based on some identifiable<lb/> piece of text, or is there a need for employing image pattern recognition software and scan each of<lb/> the images presented? And would the pattern recognition algorithms be good enough to distinguish<lb/> between a nude depicted in a work of art (not objectionable to most) and a pornographic image<lb/> (frowned upon or objectionable to many)? Assuming perfect algorithms and software implementing<lb/> </div>
	
	<note type="other">The O pen Mobile A lliance: Delivering Service Enablers forrrNext-Generation Applications </note>
	
	<byline>
	<docAuthor>M. Brenner and M. Unmehopa<lb/> </docAuthor>
	</byline>
		
	<note type="copyright">&#169; 2008 Alcatel-L ucent. All Rights Reserved. </note>
	
	<idno type="isbn">ISBN 978-0-470-51918-9<lb/> </idno>
	
	<note type="page">352<lb/> </note>
	
	<affiliation>The Open Mobile Alliance<lb/> </affiliation>
	
	<div type="introduction">these are provided, is such solution scalable (can we realistically think that every piece of content,<lb/> every text, video image, or audio soundtrack available on the Internet will be scanned, bit-by-bit to<lb/> determine what it represents)? Are legal concerns to be taken into consideration (censorship versus<lb/> privacy)?<lb/> In looking for answers, one needs to start with some undeniable facts on the ground, one of<lb/> them being the international nature of the Internet, which implies that any solutions need to rise<lb/> to that challenge, and will likely have to be a combined result of mechanisms provided by various<lb/> governments and private sector initiatives. Another fact is the need to distinguish between illegal<lb/> content and inappropriate, controversial, or otherwise objectionable content. Illegal content and/or<lb/> its use is specifically identified by (objective) existing laws (albeit the specifics may be somewhat<lb/> different from country to country), and it is applicable usually to both the physical world and<lb/> cyberspace. Typical examples of illegal content include child pornography, solicitation of children<lb/> for sexual acts, sexual harassment, violent threats, and hate propaganda. Other content may be<lb/> deemed inappropriate or objectionable on social, religious, cultural, ethnic, or other grounds to<lb/> some individuals or some communities, but it may not be illegal (although it may be harmful<lb/> if accessible to or delivered to those individuals or communities) This may include, but is not<lb/> limited to adult pornography, content rich in use of violence, drugs, alcohol. Hence, depending on<lb/> specific country legislature, proliferation of illegal content on the Internet is punishable by law,<lb/> while proliferation of other legal content, though objectionable, is not, and therefore needs to be<lb/> prevented to become harmful by other means.<lb/> While it is reassuring that at least there is a legal remedy for promoting illegal content even<lb/> on the Internet, applying a country&apos;s laws in the cyberspace is easier said than done. From a<lb/> technical perspective, content screening techniques can be applied to any content before delivering<lb/> it to its intended destination; that can be done either when a user tries to pull content, or when a<lb/> user is being pushed content. The content screening task consists of determining whether content<lb/> should be made accessible and/or should be delivered to its intended audience, and it takes into<lb/> account a combination of government regulations that address privacy concerns, local policies (e.g.<lb/> school policies, corporate policies, parental policies), and/or individual user preferences. While not<lb/> a trivial process, content screening is a manageable task, if the content to be screened has been pre-<lb/>categorized. That brings us to the notion of content categorization, or content rating â€“ the process<lb/> through which a well-defined category can be associated to a given content. The notion of content<lb/> categorization implies that there are agreed categories, as well as objective criteria to categorize<lb/> content in one of the agreed categories. It also assumes that there are effective mechanisms by which<lb/> those criteria can be applied against any given content. If that can be achieved, then any content, or<lb/> at least any content suspect of being objectionable, can be pre-categorized before screening (to speed<lb/> up the actual screening process) or categorization can be performed during the actual screening<lb/> process. Content categorization allows the screening process to simply focus on how to handle<lb/> content, based on its identified category and policies affecting its delivery. Objectionable content,<lb/> whether illegal or not, can be stopped from being harmful if a category can be assigned to it prior to<lb/> delivery. In addition to that, detecting illegal content delivery or even mere availability may result<lb/> in legal procedures and consequences. There is no doubt that content categorization is the more<lb/> difficult aspect of the overall problem, especially given the sheer amount of content available on<lb/> the Internet. While matching content in any kind of media to a category is a challenging technical<lb/> prospect, requiring sophisticated pattern searching and matching algorithms, the larger issues to<lb/> confront are related to how to establish objective criteria, who is responsible for establishing them,<lb/> and last but not least, how to deal with the sheer volume of content available, and who has the<lb/> responsibility to perform content categorization.<lb/> Voluntary rating is seen as a possible response to the responsibility and scale issues, and it is<lb/> consistent with the self-regulating nature of the Internet. Rating results in associating a pre-defined<lb/> &apos;label&apos; (category) to content, which allows the screening process to check the &apos;label&apos; (almost like</div>

		</front>
	</text>
</tei>
