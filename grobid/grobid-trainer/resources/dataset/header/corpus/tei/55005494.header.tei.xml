<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="55005494"/>
	</teiHeader>
	<text xml:lang="en">
		<front>
<lb/>
	<docTitle>
	<titlePart>UBIQUITOUS SENSING FOR POSTURE/BEHAVIOR ANALYSIS<lb/></titlePart>
	</docTitle>

	<byline>
	<docAuthor>Jeffrey L Wang, Benny L Lo, and Guang-Zhong Yang<lb/></docAuthor>
	</byline>

	<byline>
	<affiliation>Imperial College London,</affiliation>
	</byline>

	<address>The United Kingdom<lb/></address>

	<div type="abstract">ABSTRACT<lb/> Advances in body sensor networks require a combined<lb/> strategy for ambient and wearable sensing. The purpose<lb/> of this paper is to develop a pervasive visual sensing<lb/> technique for automated human behavior analysis. A<lb/> set of vision cues for posture classification is proposed<lb/> so that adverse events such as unbalanced gait or fall<lb/> can be detected. The method starts with the extraction<lb/> of human blobs and then personal metrics that lead to<lb/> behavior profiling. This provides an un-obtrusive moni-<lb/>toring environment that complements the current de-<lb/>velopment of body sensor networks.<lb/></div>

	<keyword>Keywords: posture estimation, ambient sensing, behavior<lb/> profiling, computer vision, ubiquitous sensing<lb/></keyword>

		</front>
	</text>
</tei>
