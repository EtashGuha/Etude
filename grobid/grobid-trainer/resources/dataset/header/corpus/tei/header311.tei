<tei>
	<teiHeader>
	<fileDesc xml:id="316"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Iterative Optimization and Simplification of <lb/>Hierarchical Clusterings <lb/></titlePart>
		</docTitle>
		<idno>Technical Report CS-95-01 <lb/></idno>
		<byline><docAuthor>Doug Fisher <lb/></docAuthor></byline>
		<byline><affiliation>Department of Computer Science <lb/></affiliation></byline>
		<address>Box 1679, Station B <lb/></address>
		<byline><affiliation>Vanderbilt University <lb/></affiliation></byline>
		<address>Nashville, TN 37235 <lb/></address>
		<email>dfisher@vuse.vanderbilt.edu <lb/></email>
		<ptr type="web">http://www.vuse.vanderbilt.edu/~dfisher/dfisher.html <lb/></ptr>
		<note type="phone">(615) 343-4111 <lb/></note>
		<div type="abstract">Abstract: Clustering is often used for discovering structure in data. Clustering systems <lb/>differ in the objective function used to evaluate clustering quality and the control strategy <lb/>used to search the space of clusterings. Ideally, the search strategy should consistently <lb/>construct clusterings of high quality, but be computationally inexpensive as well. In general, <lb/>we cannot have it both ways, but we can partition the search so that a system inexpensively <lb/>constructs a `tentative&apos; clustering for initial examination, followed by iterative optimization, <lb/>which continues to search in background for improved clusterings. Given this motivation, we <lb/>evaluate an inexpensive strategy for creating initial clusterings, coupled with several control <lb/>strategies for iterative optimization, each of which repeatedly modifies an initial clustering <lb/>in search of a better one. One of these methods appears novel as an iterative optimization <lb/>strategy in clustering contexts. Once a clustering has been constructed it is judged by <lb/>analysts often according to task-specific criteria. Several authors have abstracted these <lb/>criteria and posited a generic performance task akin to pattern completion, where the error <lb/>rate over completed patterns is used to `externally&apos; judge clustering utility. Given this <lb/>performance task we adapt resampling-based pruning strategies used by supervised learning <lb/>systems to the task of simplifying hierarchical clusterings, thus promising to ease post-clustering analysis. Finally, we propose a number of objective functions, based on attribute-selection measures for decision-tree induction, that might perform well on the error rate and <lb/>simplicity dimensions. <lb/></div>
		<keywords>Keywords: clustering, iterative optimization, cluster validation, resampling, pruning, objective functions. <lb/></keywords>
		<pb/>
		</front>
</text>
</tei>