<tei>
	<teiHeader>
	<fileDesc xml:id="419"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Learning to Retrieve Information <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Brian Bartell <lb/></docAuthor></byline>
		<byline><affiliation>Encylopdia Britannica and <lb/>Institute for Neural Computation <lb/>Computer Science &amp; Engineering <lb/>University of California, San Diego <lb/></affiliation></byline>
		<address>La Jolla, California 92093 <lb/></address>
		<byline><docAuthor>Garrison W. Cottrell <lb/></docAuthor></byline>
		<byline><affiliation>Institute for Neural Computation <lb/>Computer Science &amp; Engineering <lb/>University of California, San Diego <lb/></affiliation></byline>
		<address>La Jolla, California 92093 <lb/></address>
		<byline><docAuthor>Rik Belew <lb/></docAuthor></byline>
		<byline><affiliation>Institute for Neural Computation <lb/>Computer Science &amp; Engineering <lb/>University of California, San Diego <lb/></affiliation></byline>
		<address>La Jolla, California 92093 <lb/></address>
		<div type="abstract">Abstract <lb/>Information retrieval differs significantly from function approximation in that the goal is for the system to achieve the same ranking <lb/>function of documents relative to queries as the user: the outputs of <lb/>the system relative to one another must be in the proper order. We <lb/>hypothesize that a particular rank-order statistic, Guttman&apos;s point <lb/>alienation, is the proper objective function for such a system, and <lb/>demonstrate its efficacy by using it to find the optimal combination <lb/>of retrieval experts. In application to a commercial retrieval system, <lb/>the combination performs 47% better than any single expert. <lb/></div>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>