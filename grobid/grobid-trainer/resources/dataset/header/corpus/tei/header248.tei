<tei>
	<teiHeader>
	<fileDesc xml:id="249"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<byline><affiliation>MASSACHUSETTS INSTITUTE OF TECHNOLOGY <lb/>ARTIFICIAL INTELLIGENCE LABORATORY <lb/>and <lb/>CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING <lb/>DEPARTMENT OF BRAIN AND COGNITIVE SCIENCES <lb/></affiliation></byline>
		<idno>A.I. Memo No. 1565</idno>
		<date>February 2, 1996 <lb/></date>
		<idno>C.B.C.L. Memo No. 132 <lb/></idno>
		<docTitle>
			<titlePart type="main">Probabilistic Independence Networks for Hidden <lb/>Markov Probability Models <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Padhraic Smyth, David Heckerman, and Michael Jordan <lb/></docAuthor></byline>
		<div type="abstract">Abstract <lb/>Graphical techniques for modeling the dependencies of random variables have been explored in a variety <lb/>of different areas including statistics, statistical physics, artificial intelligence, speech recognition, image <lb/>processing, and genetics. Formalisms for manipulating these models have been developed relatively <lb/>independently in these research communities. In this paper we explore hidden Markov models (HMMs) <lb/>and related structures within the general framework of probabilistic independence networks (PINs). The <lb/>paper contains a self-contained review of the basic principles of PINs. It is shown that the well-known <lb/>forward-backward (F-B) and Viterbi algorithms for HMMs are special cases of more general inference <lb/>algorithms for arbitrary PINs. Furthermore, the existence of inference and estimation algorithms for <lb/>more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore <lb/>a richer class of HMM structures. Examples of relatively complex models to handle sensor fusion and <lb/>coarticulation in speech recognition are introduced and treated within the graphical model framework <lb/>to illustrate the advantages of the general approach. <lb/></div>
		<note type="copyright">Copyright c Massachusetts Institute of Technology, 1996 <lb/>This report describes research done at the Department of Information and Computer Science, University of <lb/>California, Irvine, the Jet Propulsion Laboratory, California Institute of Technology, Microsoft Research, the <lb/>Center for Biological and Computational Learning, and the Artificial Intelligence Laboratory of the Massachusetts <lb/>Institute of Technology. The authors can be contacted as pjs@aig.jpl.nasa.gov, heckerma@microsoft.com, <lb/>and jordan@psyche.mit.edu. </note>
		<note type="grant">Support for CBCL is provided in part by a grant from the NSF (ASC-9217041). <lb/>Support for the laboratory&apos;s artificial intelligence research is provided in part by the Advanced Research Projects <lb/>Agency of the Dept. of Defense. MIJ gratefully acknowledges discussions with Steffen Lauritzen on the application <lb/>of the IPF algorithm to UPINs. <lb/></note>
		<pb/>
		</front>
</text>
</tei>