<tei>
	<teiHeader>
	<fileDesc xml:id="483"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Feature Correspondence by Interleaving Shape and Texture <lb/>Computations <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>David Beymer <lb/></docAuthor></byline>
		<byline><affiliation>Artificial Intelligence Laboratory, and <lb/>Center for Biological and Computational Learning <lb/>Massachusetts Institute of Technology <lb/></affiliation></byline>
		<address>Cambridge, MA 02139, USA <lb/></address>
		<email>email: beymer@ai.mit.edu <lb/></email>
		<div type="abstract">Abstract <lb/>The correspondence problem in computer vision is basically a matching task between two or more sets of features. In this paper, we introduce a vectorized image <lb/>representation, which is a feature-based representation <lb/>where correspondence has been established with respect <lb/>to a reference image. The representation consists of two <lb/>image measurements made at the feature points: shape <lb/>and texture. Feature geometry, or shape, is represented <lb/>using the (x; ) locations of features relative to the some <lb/>standard reference shape. Image grey levels, or texture, <lb/>are represented by mapping image grey levels onto the <lb/>standard reference shape. Computing this representation <lb/>is essentially a correspondence task, and in this paper <lb/>we explore an automatic technique for &quot;vectorizing&quot; face <lb/>images. Our face vectorizer alternates back and forth <lb/>between computation steps for shape and texture, and a <lb/>key idea is to structure the two computations so that each <lb/>one uses the output of the other. In addition to describing the vectorizer, an application to the problem of facial <lb/>feature detection will be presented. <lb/></div>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>