<tei>
	<teiHeader>
	<fileDesc xml:id="unknown"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Understanding Neural Networks via Rule Extraction <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Rudy Setiono and Huan Liu <lb/></docAuthor></byline>
		<byline><affiliation>Department of Information Systems and Computer Science <lb/>National University of Singapore <lb/></affiliation></byline>
		<address>Kent Ridge, Singapore 0511 <lb/></address>
		<email>frudys,liuhg@iscs.nus.sg <lb/></email>
		<div type="abstract">Abstract <lb/>Although backpropagation neural networks <lb/>generally predict better than decision trees do <lb/>for pattern classification problems, they are often regarded as black boxes, i.e., their predictions are not as interpretable as those of decision trees. This paper argues that this is because there has been no proper technique that <lb/>enables us to do so. With an algorithm that <lb/>can extract rules 1 , by drawing parallels with <lb/>those of decision trees, we show that the predictions of a network can be explained via rules extracted from it, thereby, the network can be understood. Experiments demonstrate that rules <lb/>extracted from neural networks are comparable with those of decision trees in terms of predictive accuracy, number of rules and average <lb/>number of conditions for a rule; they preserve <lb/>high predictive accuracy of original networks. <lb/></div>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>