<tei>
	<teiHeader>
	<fileDesc xml:id="555"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">NIFDY: A Low Overhead, High Throughput Network Interface <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Timothy Callahan and Seth Copen Goldstein <lb/></docAuthor></byline>
		<email>{timothyc,sethg}@cs.berkeley.edu <lb/></email>
		<byline><affiliation>Computer Science Division <lb/>University of California-Berkeley <lb/></affiliation></byline>
		<div type="abstract">Abstract <lb/>In this paper we present NIFDY, a network interface that uses admission control to reduce congestion and ensures that packets are <lb/>received by a processor in the order in which they were sent, even <lb/>if the underlying network delivers the packets out of order. The <lb/>basic idea behind NIFDY is that each processor is allowed to have at <lb/>most one outstanding packet to any other processor unless the destination processor has granted the sender the right to send multiple <lb/>unacknowledged packets. Further, there is a low upper limit on the <lb/>number of outstanding packets to all processors. <lb/>We present results from simulations of a variety of networks <lb/>(meshes, tori, butterflies, and fat trees) and traffic patterns to verify NIFDY&apos;s efficacy. Our simulations show that NIFDY increases <lb/>throughput and decreases overhead. The utility of NIFDY increases <lb/>as a network&apos;s bisection bandwidth decreases. When combined <lb/>with the increased payload allowed by in-order delivery NIFDY increases total bandwidth delivered for all networks. The resources <lb/>needed to implement NIFDY are small and constant with respect to <lb/>network size. <lb/></div>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>