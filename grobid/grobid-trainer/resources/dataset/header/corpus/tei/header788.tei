<tei>
	<teiHeader>
	<fileDesc xml:id="789"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">MINIMIZING MEMORY CACHE USAGE FOR MULTIGRID <lb/>ALGORITHMS IN TWO DIMENSIONS <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>CRAIG C. DOUGLAS <lb/></docAuthor></byline>
		<div type="abstract">Abstract. Computers today rely heavily on good utilization of their cache memory subsystems. <lb/>Compilers are optimized for business applications, not scientific computing ones, however. Automatic <lb/>tiling of basic numerical algorithms is simply not provided by any compiler. Thus, absolutely terrible <lb/>cache performance is normal for scientific computing applications. <lb/>Multigrid algorithms combine several numerical algorithms into a more complicated algorithm. <lb/>In this paper, an algorithm is derived that allows for data to pass through cache exactly once per <lb/>multigrid level during a V cycle before the level changes. This is optimal cache usage for large <lb/>problems that do not fit entirely in cache. <lb/>The new algorithm would appear to be quite complicated to implement, leading to spaghetti <lb/>coding. Actually, an efficient implementation of the algorithm requires a rigid, highly structured <lb/>coding style. A coding example is given that is suitable for almost all common discretization methods. <lb/>Numerical experiments are provided that show that the new algorithm is up to an integer factor <lb/>faster than the traditional implementation method for common multigrid parameter choices. <lb/></div>
		<keywords>Key words. multigrid, cache, threads, sparse matrix, iterative methods, domain decomposition, <lb/>compiler optimization. <lb/></keywords>
		<keywords type="classes">AMS subject classifications. 65N15, 65N10 <lb/></keywords>
		<div type="intro">1. Introduction.</div>
		</front>
</text>
</tei>