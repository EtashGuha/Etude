<tei>
	<teiHeader>
	<fileDesc xml:id="228"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">MULTIMEDIA MEETS MACHINE LEARNING <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>STEFAN M UNCH <lb/></docAuthor></byline>
		<byline><affiliation>Institute for Real-Time Computer Systems &amp; Robotics, University of Karlsruhe,</affiliation></byline>
		<address>Kaiserstr. 12, <lb/>D-76128 Karlsruhe, Germany. <lb/></address>
		<div type="abstract">Abstract. The application of Machine Learning techniques to multimedia and multimodal systems, <lb/>resp., seems to be a promising approach in order to enhance the systems&apos; capabilities. Especially <lb/>in multimodal systems which support human-computer interaction (HCI) via several input/output <lb/>channels in parallel, intelligent mechanisms are needed in order to process the user&apos;s inputs and to <lb/>select the best output modality. <lb/>In this paper, we will deal with a multi-agent system which introduces some kind of haptic feedback <lb/>to the user interface. The main task of the system is to predict the next user action in order to launch <lb/>the haptic feedback selectively and to adapt this capability over time to both, the user&apos;s behavior <lb/>and the application&apos;s user interface structure. Therefore, a statistical interaction model is generated <lb/>and managed based on stochastic classification methods. <lb/></div>
		<keywords>Key Words. Multimedia, Multimodality, Haptic Output, Man-Machine-Systems, Human-Computer Interaction, Classification, User Modelling <lb/></keywords>
		<div type="intro">1 INTRODUCTION</div>
		</front>
</text>
</tei>