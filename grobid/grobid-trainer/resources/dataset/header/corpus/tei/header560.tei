<tei>
	<teiHeader>
	<fileDesc xml:id="563"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Goal-Directed Classification using Linear Machine <lb/>Decision Trees * <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Bruce A. Draper Carla E. Brodley Paul E. Utgoff <lb/></docAuthor></byline>
		<byline><affiliation>Department of Computer Science <lb/>University of Massachusetts <lb/></affiliation></byline>
		<address>Amherst, MA., USA. 01003 <lb/></address>
		<email>bdraper@cs.umass.edu <lb/></email>
		<date>September 17, 1993 <lb/></date>
		<div type="abstract">Abstract <lb/>Recent work in feature-based classification has focused on non-parametric techniques that can classify instances even when the underlying feature distributions are <lb/>unknown. The inference algorithms for training these techniques, however, are designed <lb/>to maximize the accuracy of the classifier, with all errors weighted equally. In many <lb/>applications, certain errors are far more costly than others, and the need arises for <lb/>non-parametric classification techniques that can be trained to optimize task-specific <lb/>cost functions. This paper reviews the Linear Machine Decision Tree (LMDT) algorithm for inducing multivariate decision trees, and shows how LMDT can be altered to <lb/>induce decision trees that minimize arbitrary misclassification cost functions (MCFs). <lb/>Demonstrations of pixel classification in outdoor scenes show how MCFs can optimize <lb/>the performance of embedded classifiers within the context of larger image understand <lb/>ing systems. <lb/></div>
		<keywords>Keywords: Decision Trees, Non-Parametric Classification, Pattern Recognition, Object Recognition, Computer Vision, Machine Learning. <lb/></keywords>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>