<tei>
	<teiHeader>
	<fileDesc xml:id="72"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<note type="reference">As appears in Neural Information Processing Systems 4, pp. 251-258, 1992. <lb/></note>
		<docTitle>
			<titlePart type="main">The Efficient Learning of Multiple Task <lb/>Sequences <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Satinder P. Singh <lb/></docAuthor></byline>
		<byline><affiliation>Department of Computer Science <lb/> University of Massachusetts <lb/></affiliation></byline>
		<address>Amherst, MA 01003 <lb/></address>
		<div type="abstract">Abstract <lb/>I present a modular network architecture and a learning algorithm based <lb/>on incremental dynamic programming that allows a single learning agent <lb/>to learn to solve multiple Markovian decision tasks (MDTs) with significant transfer of learning across the tasks. I consider a class of MDTs, <lb/>called composite tasks, formed by temporally concatenating a number of <lb/>simpler, elemental MDTs. The architecture is trained on a set of composite and elemental MDTs. The temporal structure of a composite task is <lb/>assumed to be unknown and the architecture learns to produce a temporal decomposition. It is shown that under certain conditions the solution <lb/>of a composite MDT can be constructed by computationally inexpensive <lb/>modifications of the solutions of its constituent elemental MDTs. <lb/></div>
		<div type="intro">1 INTRODUCTION</div>
		</front>
</text>
</tei>