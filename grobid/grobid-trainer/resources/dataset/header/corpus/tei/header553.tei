<tei>
	<teiHeader>
	<fileDesc xml:id="556"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">Implementing Bit-addressing with Specialization <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Scott Draves <lb/></docAuthor></byline>
		<byline><affiliation>School of Computer Science <lb/>Carnegie Mellon University <lb/></affiliation></byline>
		<address>5000 Forbes Avenue, Pittsburgh, PA 15213, USA <lb/></address>
		<div type="abstract">Abstract <lb/>General media-processing programs are easily expressed with bit-addressing and variable-sized bit-fields. But the natural implementation of bit-addressing relies on dynamic shift offsets and repeated <lb/>loads, resulting in slow execution. If the code is specialized to the <lb/>alignment of the data against word boundaries, the offsets become <lb/>static and many repeated loads can be removed. We show how introducing modular arithmetic into an automatic compiler generator <lb/>enables the transformation of a program that uses bit-addressing <lb/>into a synthesizer of fast specialized programs. <lb/>In partial-evaluation jargon we say: modular arithmetic is supported by extending the binding time lattice used by the static analysis in a polyvariant compiler generator. The new binding time <lb/>Cyclic functions like a partially static integer. <lb/>A software cache combined with a fast, optimistic sharing analysis built into the compilers eliminates repeated loads and stores. <lb/>The utility of the transformation is demonstrated with a collection <lb/>of examples and benchmark data. The examples include vector <lb/>arithmetic, audio synthesis, image processing, and a base-64 codec. <lb/></div>
		<div type="intro">1 Introduction</div>
		</front>
</text>
</tei>